{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d618d77f-c31a-4b19-adde-006220139802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving data for Amsterdam...\n",
      "All checks passed.\n",
      "Retrieving data for Athens...\n",
      "All checks passed.\n",
      "Retrieving data for Belgrade...\n",
      "All checks passed.\n",
      "Retrieving data for Berlin...\n",
      "All checks passed.\n",
      "Retrieving data for Brussels...\n",
      "All checks passed.\n",
      "Retrieving data for Budapest...\n",
      "All checks passed.\n",
      "Retrieving data for Copenhagen...\n",
      "All checks passed.\n",
      "Retrieving data for Dublin...\n",
      "All checks passed.\n",
      "Retrieving data for Helsinki...\n",
      "All checks passed.\n",
      "Retrieving data for Lisbon...\n",
      "All checks passed.\n",
      "Retrieving data for London...\n",
      "All checks passed.\n",
      "Retrieving data for Madrid...\n",
      "All checks passed.\n",
      "Retrieving data for Moscow...\n",
      "All checks passed.\n",
      "Retrieving data for Oslo...\n",
      "All checks passed.\n",
      "Retrieving data for Paris...\n",
      "All checks passed.\n",
      "Retrieving data for Prague...\n",
      "All checks passed.\n",
      "Retrieving data for Riga...\n",
      "All checks passed.\n",
      "Retrieving data for Rome...\n",
      "All checks passed.\n",
      "Retrieving data for Stockholm...\n",
      "All checks passed.\n",
      "Retrieving data for Vienna...\n",
      "All checks passed.\n",
      "Retrieving data for Zagreb...\n",
      "All checks passed.\n",
      "The integrated data '15-05-2025_data.json' has been saved in the 'file_jason_aqi' folder.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "\n",
    "#function to get whather contintion for each city\n",
    "def get_weather(city, api_key):\n",
    "    url = f\"http://api.weatherapi.com/v1/current.json?key={api_key}&q={city}&aqi=no\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:   #code for successfully request\n",
    "        data = response.json()\n",
    "        return {\n",
    "            'City': city,\n",
    "            'Temperature': data['current']['temp_c'],  #celsius degree\n",
    "            'Condition': data['current']['condition']['text'], #weather condition descricption\n",
    "            'Humidity': data['current']['humidity'], #humidity (%)\n",
    "            'Wind Speed': data['current']['wind_kph'] #wind speed (km/h)\n",
    "        }\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for {city}. Status code and status text:{response.status_code} - {response.text}\")    \n",
    "        return None\n",
    "\n",
    "# Function to get air quality data for each city\n",
    "def get_air_quality_data(city, state, country, api_key):\n",
    "    url = f\"https://api.airvisual.com/v2/city?city={city}&state={state}&country={country}&key={api_key}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:  # Successful request\n",
    "        data = response.json()\n",
    "        \n",
    "        if data['status'] == \"success\":\n",
    "            city_data = data['data']   #access to data\n",
    "            return {\n",
    "                \"city\": city_data['city'],  \n",
    "                \"state\": city_data['state'],\n",
    "                \"country\": city_data['country'],\n",
    "                \"AQI\": city_data['current']['pollution']['aqius'],  # US measurement for air quality index\n",
    "                \"pollutants\": city_data['current']['pollution']     # other pollution measurement \n",
    "                \n",
    "            }\n",
    "    else:\n",
    "        print(f\"Error retrieving data for {city}: {response.status_code} - {response.text}\")\n",
    "\n",
    "    return None\n",
    "\n",
    "# API Keys\n",
    "weather_api_key = 'INSERT_API_KEY_1'\n",
    "air_quality_api_key = \"INSERT_API_KEY_2\"\n",
    "\n",
    "\n",
    "cities = [\n",
    "    (\"Amsterdam\", \"North Holland\", \"Netherlands\"),\n",
    "    (\"Athens\", \"Attica\", \"Greece\"),\n",
    "    (\"Belgrade\", \"Central Serbia\", \"Serbia\"),\n",
    "    (\"Berlin\", \"Berlin\", \"Germany\"),\n",
    "    (\"Brussels\", \"Brussels Capital\", \"Belgium\"),\n",
    "    (\"Budapest\", \"Central Hungary\", \"Hungary\"),\n",
    "    (\"Copenhagen\", \"Capital Region\", \"Denmark\"),\n",
    "    (\"Dublin\", \"Leinster\", \"Ireland\"),\n",
    "    (\"Helsinki\", \"Uusimaa\", \"Finland\"),\n",
    "    (\"Lisbon\", \"Lisbon\", \"Portugal\"),\n",
    "    (\"London\", \"England\", \"United Kingdom\"),\n",
    "    (\"Madrid\", \"Madrid\", \"Spain\"),\n",
    "    (\"Moscow\", \"Moscow\", \"Russia\"),\n",
    "    (\"Oslo\", \"Oslo\", \"Norway\"),\n",
    "    (\"Paris\", \"ÃŽle-de-France\", \"France\"),\n",
    "    (\"Prague\", \"Praha\", \"Czech Republic\"),\n",
    "    (\"Riga\", \"Riga\", \"Latvia\"),\n",
    "    (\"Rome\", \"Latium\", \"Italy\"),\n",
    "    (\"Stockholm\", \"Stockholm\", \"Sweden\"),\n",
    "    (\"Vienna\", \"Vienna\", \"Austria\"),\n",
    "    (\"Zagreb\", \"Zagreb\", \"Croatia\")\n",
    "]\n",
    "\n",
    "# dictionary for storing city data\n",
    "documents = {}\n",
    "list_doc=[] #use a list due to have for each city one document\n",
    "# today's date\n",
    "today_date = datetime.now().strftime('%d-%m-%Y')  \n",
    "\n",
    "weather_fields = ['City', 'Temperature', 'Condition', 'Humidity', 'Wind Speed']\n",
    "air_quality_fields = ['city', 'state', 'country', 'AQI', 'pollutants']\n",
    "\n",
    "\n",
    "for capitale, stato, paese in cities:\n",
    "    print(f\"Retrieving data for {capitale}...\")\n",
    "    \n",
    "    air_quality_info = get_air_quality_data(capitale, stato, paese, air_quality_api_key)\n",
    "    weather_info = get_weather(capitale, weather_api_key)\n",
    "    \n",
    "    # Data validation\n",
    "    if air_quality_info and weather_info:    # check if there are non-None values\n",
    "#####################################################################################################\n",
    "# DATA QUALITY CHECKS        \n",
    "#####################################################################################################\n",
    "# Check for required fields\n",
    "            if (all(field in weather_info for field in weather_fields) and\n",
    "                all(field in air_quality_info for field in air_quality_fields)):\n",
    "            \n",
    "                # Check data types and values consistency\n",
    "                if (isinstance(weather_info['Temperature'], (int, float)) and \n",
    "                    isinstance(weather_info['Humidity'], (int, float)) and \n",
    "                    isinstance(weather_info['Wind Speed'], (int, float)) and \n",
    "                    isinstance(air_quality_info['AQI'], (int, float)) and\n",
    "                    weather_info['Humidity'] >= 0 and \n",
    "                    weather_info['Wind Speed'] >= 0 and\n",
    "                    air_quality_info['AQI'] >= 0):\n",
    "                    print(\"All checks passed.\")\n",
    "                    documents[capitale] = {\n",
    "                        capitale: {\n",
    "                            today_date: {\n",
    "                                'Air Quality': air_quality_info,\n",
    "                                'Weather': weather_info\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                    list_doc.append(documents[capitale])\n",
    "                else:\n",
    "                    print(f\"Invalid data types or data inconsistency for {capitale}.\")\n",
    "            else:\n",
    "                print(f\"Missing fields in data for {capitale}.\")\n",
    "#####################################################################################\n",
    "# END DATA QUALITY CHECKS\n",
    "#####################################################################################\n",
    "\n",
    "    time.sleep(13) # Minimum delay to avoid exceeding request limit\n",
    "#folder path where the data will store\n",
    "# to save the file in the folder of interest, simply call the file with the path where you want to save the file\n",
    "output_directory = \".../file_jason_aqi/\" \n",
    "\n",
    "#os.path.join to join the folder path and file name\n",
    "output_filename = os.path.join(output_directory, f\"{today_date}_data.json\")\n",
    "\n",
    "\n",
    "with open(output_filename, 'w') as json_file:\n",
    "    json.dump(list_doc, json_file, indent=4)\n",
    "\n",
    "print(f\"The integrated data '{today_date}_data.json' has been saved in the 'file_jason_aqi' folder.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd123f15-3ca2-4ca2-8e2a-6899b3f15bb0",
   "metadata": {},
   "source": [
    "## Merge the historical JSON files in one single JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e17d718-c9a9-43c7-aed4-c4a417dd7f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data saved as 'city_weather_aqi.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def combine_json_files_from_folder(folder_path, output_file):\n",
    "    combined_data = []  # list due to have for each day one document\n",
    "\n",
    "    # Iteration for each JSON file in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.json'):  \n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "                \n",
    "                for element in data:\n",
    "                    for city, daily_data in element.items():\n",
    "                        for date, details in daily_data.items():\n",
    "                            # Check if data already exists\n",
    "                            date_entry = next((item for item in combined_data if date in item), None)\n",
    "\n",
    "                            if date_entry is None:\n",
    "                                # Create a new entry for the date if it does not exist\n",
    "                                date_entry = {date: {}}\n",
    "                                combined_data.append(date_entry)\n",
    "                            ##########################################################################\n",
    "                            #deleting redundant data\n",
    "                            ###########################################################################                            \n",
    "                            air_quality = details['Air Quality']\n",
    "                            if 'city' in air_quality:\n",
    "                                del air_quality['city']\n",
    "                               \n",
    "                            weather = details['Weather']\n",
    "                            if 'City' in weather:\n",
    "                                del weather['City']\n",
    "                            pollutants = air_quality['pollutants']   \n",
    "                            if 'ts' in pollutants:\n",
    "                                del pollutants['ts']\n",
    "\n",
    "                            # Add the city and details as a key in the date dictionary\n",
    "                            date_entry[date][city] = {\n",
    "                                \"details\": details\n",
    "                            }\n",
    "\n",
    "    # final JSON file\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(combined_data, f, indent=4)\n",
    "\n",
    "    print(f\"Combined data saved as 'city_weather_aqi.json'\")\n",
    "\n",
    "folder_path = '.../file_jason_aqi'  \n",
    "output_file = '.../city_weather_aqi.json'\n",
    "combine_json_files_from_folder(folder_path, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d375723-eff1-42c5-bc77-b133adc454d8",
   "metadata": {},
   "source": [
    "# Data Enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdd7b8e8-c0d7-4240-b2d4-44b05a9a78bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved enriched data as 'enriched_data.json'.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "combined_data_path = \".../city_weather_aqi.json\"\n",
    "\n",
    "with open(combined_data_path, 'r') as file:\n",
    "    data = json.load(file)  \n",
    "\n",
    "def enrich_data(data):\n",
    "    for date_record in data:\n",
    "        for date, cities in date_record.items():\n",
    "            for city, details in cities.items():\n",
    "                aqi = details['details']['Air Quality']['AQI']\n",
    "                # the following descriptions are taken from https://www.airnow.gov/aqi/aqi-basics/\n",
    "                if aqi <= 50:\n",
    "                    description = 'Good'\n",
    "                elif aqi <= 100:\n",
    "                    description = 'Moderate'\n",
    "                elif aqi <= 150:\n",
    "                    description = 'Unhealthy for Sensitive Groups'\n",
    "                elif aqi <= 200:\n",
    "                    description = 'Unhealthy'\n",
    "                elif aqi <= 300:\n",
    "                    description = 'Very Unhealthy'\n",
    "                else:\n",
    "                    description = 'Hazardous'\n",
    "                details['details']['Air Quality']['Description'] = description\n",
    "    return data\n",
    "\n",
    "enriched_data = enrich_data(data)\n",
    "\n",
    "enriched_data_json = json.dumps(enriched_data, indent=4)\n",
    "output_file_path = \".../enriched_data.json\" #download file\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    json.dump(enriched_data, output_file, indent=4)\n",
    "print(f\"Saved enriched data as 'enriched_data.json'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bacbcb-908f-4073-8ae1-f12e4ad0ef5d",
   "metadata": {},
   "source": [
    "# Data Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "662d0167-077e-4ca0-a0a3-20d2c1f2725a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in c:\\users\\hp\\anaconda32\\lib\\site-packages (4.10.1)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\hp\\anaconda32\\lib\\site-packages (from pymongo) (2.7.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98bacb9e-636e-478c-9de9-34f59f5212d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InsertManyResult([ObjectId('6825c8300e3b6220b77b7432'), ObjectId('6825c8300e3b6220b77b7433'), ObjectId('6825c8300e3b6220b77b7434'), ObjectId('6825c8300e3b6220b77b7435'), ObjectId('6825c8300e3b6220b77b7436'), ObjectId('6825c8300e3b6220b77b7437'), ObjectId('6825c8300e3b6220b77b7438'), ObjectId('6825c8300e3b6220b77b7439'), ObjectId('6825c8300e3b6220b77b743a'), ObjectId('6825c8300e3b6220b77b743b'), ObjectId('6825c8300e3b6220b77b743c'), ObjectId('6825c8300e3b6220b77b743d'), ObjectId('6825c8300e3b6220b77b743e'), ObjectId('6825c8300e3b6220b77b743f'), ObjectId('6825c8300e3b6220b77b7440'), ObjectId('6825c8300e3b6220b77b7441'), ObjectId('6825c8300e3b6220b77b7442'), ObjectId('6825c8300e3b6220b77b7443'), ObjectId('6825c8300e3b6220b77b7444'), ObjectId('6825c8300e3b6220b77b7445'), ObjectId('6825c8300e3b6220b77b7446'), ObjectId('6825c8300e3b6220b77b7447'), ObjectId('6825c8300e3b6220b77b7448'), ObjectId('6825c8300e3b6220b77b7449'), ObjectId('6825c8300e3b6220b77b744a'), ObjectId('6825c8300e3b6220b77b744b'), ObjectId('6825c8300e3b6220b77b744c'), ObjectId('6825c8300e3b6220b77b744d'), ObjectId('6825c8300e3b6220b77b744e'), ObjectId('6825c8300e3b6220b77b744f'), ObjectId('6825c8300e3b6220b77b7450'), ObjectId('6825c8300e3b6220b77b7451'), ObjectId('6825c8300e3b6220b77b7452'), ObjectId('6825c8300e3b6220b77b7453'), ObjectId('6825c8300e3b6220b77b7454'), ObjectId('6825c8300e3b6220b77b7455'), ObjectId('6825c8300e3b6220b77b7456'), ObjectId('6825c8300e3b6220b77b7457'), ObjectId('6825c8300e3b6220b77b7458'), ObjectId('6825c8300e3b6220b77b7459'), ObjectId('6825c8300e3b6220b77b745a'), ObjectId('6825c8300e3b6220b77b745b'), ObjectId('6825c8300e3b6220b77b745c'), ObjectId('6825c8300e3b6220b77b745d'), ObjectId('6825c8300e3b6220b77b745e'), ObjectId('6825c8300e3b6220b77b745f'), ObjectId('6825c8300e3b6220b77b7460'), ObjectId('6825c8300e3b6220b77b7461'), ObjectId('6825c8300e3b6220b77b7462'), ObjectId('6825c8300e3b6220b77b7463'), ObjectId('6825c8300e3b6220b77b7464'), ObjectId('6825c8300e3b6220b77b7465'), ObjectId('6825c8300e3b6220b77b7466'), ObjectId('6825c8300e3b6220b77b7467'), ObjectId('6825c8300e3b6220b77b7468'), ObjectId('6825c8300e3b6220b77b7469'), ObjectId('6825c8300e3b6220b77b746a'), ObjectId('6825c8300e3b6220b77b746b'), ObjectId('6825c8300e3b6220b77b746c'), ObjectId('6825c8300e3b6220b77b746d'), ObjectId('6825c8300e3b6220b77b746e'), ObjectId('6825c8300e3b6220b77b746f'), ObjectId('6825c8300e3b6220b77b7470'), ObjectId('6825c8300e3b6220b77b7471'), ObjectId('6825c8300e3b6220b77b7472'), ObjectId('6825c8300e3b6220b77b7473'), ObjectId('6825c8300e3b6220b77b7474'), ObjectId('6825c8300e3b6220b77b7475'), ObjectId('6825c8300e3b6220b77b7476'), ObjectId('6825c8300e3b6220b77b7477'), ObjectId('6825c8300e3b6220b77b7478')], acknowledged=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client['weather_db']  #create db\n",
    "collection = db['weather_data']  # creat collection\n",
    "\n",
    "# saving data\n",
    "with open(\".../enriched_data.json\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# insert dato into collection\n",
    "collection.insert_many(data) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bf265b-cd17-4c69-a127-592532b6840c",
   "metadata": {},
   "source": [
    "# Query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebce992d-cb1d-4b47-8a2d-efeb9de229f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Air Quality in Amsterdam on 05-03-2025: {'state': 'North Holland', 'country': 'Netherlands', 'AQI': 149, 'pollutants': {'aqius': 149, 'mainus': 'p2', 'aqicn': 75, 'maincn': 'p2'}, 'Description': 'Unhealthy for Sensitive Groups'}\n"
     ]
    }
   ],
   "source": [
    "city = \"Amsterdam\"\n",
    "date = \"05-03-2025\"\n",
    "result = collection.find_one({date: {\"$exists\": True}})\n",
    "if result:\n",
    "    air_quality = result[date][city]['details']['Air Quality']\n",
    "    print(f\"Air Quality in {city} on {date}: {air_quality}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fade0c65-7fe6-4a31-ba7f-82c8b0ff503c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Which day do you want analyze?  05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day: 05\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Which month do you want analyze?  03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month: 03\n",
      "Correlation beteween Â°C and AQI: 0.153\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "def temp_aqi_correlation(date_str):\n",
    "    query = {date_str: {\"$exists\": True}}\n",
    "    result = collection.find_one(query)\n",
    "    \n",
    "    if result:\n",
    "        l_temp = []\n",
    "        l_aqi = []\n",
    "        \n",
    "        for city_name, data in result[date_str].items():\n",
    "                temp = data['details']['Weather']['Temperature']\n",
    "                aqi = data['details']['Air Quality']['AQI']\n",
    "                l_temp.append(temp)\n",
    "                l_aqi.append(aqi)\n",
    "\n",
    "        \n",
    "        if l_temp and l_aqi:\n",
    "            correlation = np.corrcoef(l_temp, l_aqi)[0, 1]\n",
    "            cor_3 = round(correlation,3)\n",
    "            print(f\"Correlation beteween Â°C and AQI: {cor_3}\")\n",
    "            return correlation\n",
    "\n",
    "\n",
    "day=input(\"Which day do you want analyze? \")\n",
    "print(f\"Day: {day}\")\n",
    "if day not in [f\"{i:02d}\" for i in range(1, 32)]:\n",
    "    print(\"Invalid input. Please enter a valid month between 01 and 31.\") \n",
    "    sys.exit()\n",
    "\n",
    "month= input(\"Which month do you want analyze? \")\n",
    "print(f\"Month: {month}\")\n",
    "if month not in [f\"{i:02d}\" for i in range(1, 13)]:\n",
    "    print(\"Invalid input. Please enter a valid day between 01 and 12.\")\n",
    "    sys.exit()\n",
    "date = f\"{day}-{month}-2025\"\n",
    "correlation = temp_aqi_correlation(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbe4872c-f72d-4646-8b5a-fe999ff2794d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Which day do you want to analyze?  05\n",
      "Which month do you want to analyze?  05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Windest cities:\n",
      "Amsterdam: 24.5 km/h, AQI: 29\n",
      "Lisbon: 23.0 km/h, AQI: 28\n",
      "Helsinki: 22.0 km/h, AQI: 30\n",
      "London: 21.2 km/h, AQI: 27\n",
      "Brussels: 20.5 km/h, AQI: 36\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def windiest_cities(date_str):\n",
    "    query = {date_str: {\"$exists\": True}}\n",
    "    result = collection.find_one(query)\n",
    "    \n",
    "    if result:\n",
    "        cities_data = []\n",
    "        for city_name, data in result[date_str].items():\n",
    "\n",
    "                wind_speed = data['details']['Weather']['Wind Speed']\n",
    "                cities_data.append({\n",
    "                    'city': city_name,\n",
    "                    'wind_speed': wind_speed,\n",
    "                    'aqi': data['details']['Air Quality']['AQI']\n",
    "                })\n",
    "\n",
    "        \n",
    "        sorted_cities = sorted(cities_data, key=lambda x: x['wind_speed'], reverse=True)\n",
    "        return sorted_cities[:5] #first 5 rows \n",
    "\n",
    "\n",
    "\n",
    "day = input(\"Which day do you want to analyze? \")\n",
    "#print(f\"Day: {day}\")\n",
    "if day not in [f\"{i:02d}\" for i in range(1, 32)]:\n",
    "    print(\"Invalid input. Please enter a valid day between 01 and 31.\") \n",
    "    sys.exit()\n",
    "\n",
    "month = input(\"Which month do you want to analyze? \")\n",
    "#print(f\"Month: {month}\")\n",
    "if month not in [f\"{i:02d}\" for i in range(1, 13)]:\n",
    "    print(\"Invalid input. Please enter a valid month between 01 and 12.\")\n",
    "    sys.exit()\n",
    "\n",
    "date = f\"{day}-{month}-2025\"\n",
    "windy_cities = windiest_cities(date)\n",
    "print(\"\\n\")\n",
    "print(\"Windest cities:\")\n",
    "for city in windy_cities:\n",
    "    print(f\"{city['city']}: {city['wind_speed']} km/h, AQI: {city['aqi']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71c3489f-6c15-4d2a-ac28-ce0bf3be5b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Which day do you want to analyze?  13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day: 13\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Which month do you want to analyze?  04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month: 04\n",
      "\n",
      "\n",
      "Cities with the worst air quality index on 13-04-2025:\n",
      "Amsterdam: AQI 86, Temperature 14.2Â°C\n",
      "London: AQI 73, Temperature 16.1Â°C\n",
      "Copenhagen: AQI 63, Temperature 9.0Â°C\n",
      "Paris: AQI 57, Temperature 15.3Â°C\n",
      "Prague: AQI 57, Temperature 18.3Â°C\n"
     ]
    }
   ],
   "source": [
    "def worst_aqi_cities(date_str, limit=5):\n",
    "    query = {date_str: {\"$exists\": True}}\n",
    "    result = collection.find_one(query)\n",
    "    \n",
    "    if result:\n",
    "        cities_data = []\n",
    "        for city_name, data in result[date_str].items():\n",
    "            aqi = data['details']['Air Quality']['AQI']\n",
    "            cities_data.append({\n",
    "                'city': city_name,\n",
    "                'aqi': aqi,\n",
    "                'temperature': data['details']['Weather']['Temperature']\n",
    "            })\n",
    "        sorted_cities = sorted(cities_data, key=lambda x: x['aqi'], reverse=True)\n",
    "        return sorted_cities[:limit]\n",
    "\n",
    "day = input(\"Which day do you want to analyze? \")\n",
    "print(f\"Day: {day}\")\n",
    "if day not in [f\"{i:02d}\" for i in range(1, 32)]:\n",
    "    print(\"Invalid input. Please enter a valid day between 01 and 31.\") \n",
    "    sys.exit()\n",
    "\n",
    "month = input(\"Which month do you want to analyze? \")\n",
    "print(f\"Month: {month}\")\n",
    "if month not in [f\"{i:02d}\" for i in range(1, 13)]:\n",
    "    print(\"Invalid input. Please enter a valid month between 01 and 12.\")\n",
    "    sys.exit()\n",
    "\n",
    "print(\"\\n\")\n",
    "date = f\"{day}-{month}-2025\"\n",
    "worst_cities = worst_aqi_cities(date)\n",
    "\n",
    "if worst_cities:  # Check if the list is not empty\n",
    "    print(f\"Cities with the worst air quality index on {date}:\")\n",
    "    for city in worst_cities:\n",
    "        print(f\"{city['city']}: AQI {city['aqi']}, Temperature {city['temperature']}Â°C\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
